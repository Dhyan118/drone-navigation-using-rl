# Drone Pathfinding and Navigation Using Reinforcement Learning

This project implements an autonomous drone navigation system in a grid-based environment, combining classical pathfinding techniques with reinforcement learning to achieve efficient and intelligent navigation. The drone learns to reach a target location while avoiding obstacles and minimizing path cost through both algorithmic planning and learned policies.

## Table of Contents
- Features  
- Project Components  
- Setup Instructions  
- Usage  
- Visualizations  
- Reinforcement Learning Model  
- Evaluation  
- License  

---

## Features
- Classical Pathfinding using A* Algorithm for optimal shortest-path planning  
- Reinforcement Learning–based navigation for adaptive decision-making  
- Obstacle-aware navigation in a grid environment  
- Multiple visualizations including static paths, heatmaps, animations, and 3D plots  
- Step-by-step drone movement visualization  

---

## Project Components
- **Pathfinding Module**  
  Implements the A* search algorithm along with helper utilities for computing optimal paths in a grid.

- **Reinforcement Learning Module**  
  Defines a custom OpenAI Gym environment where the drone learns navigation policies through interaction with the environment.

- **Visualization Module**  
  Provides multiple visualization utilities to analyze navigation behavior, path costs, and learning outcomes.

---

## Setup Instructions

Clone the repository:

git clone https://github.com/Dhyan118/drone-navigation-using-rl.git
cd drone-navigation-using-rl


##Install dependencies:

pip install -r requirements.txt

Usage: 
  1. Define the drone’s starting position, target location, and obstacle coordinates.
  2. Choose a navigation approach:
      Classical A* pathfinding
      Reinforcement learning–based navigation
  3. Run the Jupyter notebook to observe navigation behavior and visual outputs.
Visualizations

The project includes several visualization techniques to better understand the navigation process:
1. Environment Setup
Displays the grid environment with start position, target, and obstacles.

2. Static Path Visualization
Shows the optimal path generated by the A* algorithm.

3. Path Cost Heatmap
Visualizes traversal costs across the grid to highlight challenging regions.

4. Dynamic Navigation Animation
Animates the drone’s step-by-step movement toward the target.

5. 3D Cost Surface Plot
Represents navigation costs as a 3D surface for deeper analysis.

Reinforcement Learning Model:
In addition to classical pathfinding, the project uses reinforcement learning to allow the drone to learn navigation strategies dynamically.

RL Environment
The custom Gym environment:
 Defines discrete actions including cardinal and diagonal movements
 Uses a reward function that:
 Rewards reaching the target
 Penalizes collisions and inefficient movements
 Encourages exploration before converging on optimal policies

 
Training Example
from stable_baselines3 import PPO

env = DroneEnv()
model = PPO("MlpPolicy", env, verbose=1)
model.learn(total_timesteps=10000)
Evaluation
After training, the RL agent navigates autonomously using learned policies, adapting its path based on environmental feedback. This approach demonstrates how learning-based navigation can complement traditional pathfinding methods, especially in dynamic or uncertain environments.

